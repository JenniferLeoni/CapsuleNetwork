{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4a1a7b2-9e84-45cc-8eaa-27e31ae5923d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (0.1.73)\n",
      "Requirement already satisfied: transformers in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (4.52.4)\n",
      "Requirement already satisfied: torch in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (2.7.0)\n",
      "Requirement already satisfied: tqdm in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (4.67.1)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: filelock in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from transformers) (0.32.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: setuptools in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from torch) (71.0.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from torch) (3.3.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: anyascii in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
      "Requirement already satisfied: pyahocorasick in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from textsearch>=0.0.21->contractions) (2.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/c14210092/Hallo_portrait_image_animation/halloenv2/lib/python3.12/site-packages (from requests->transformers) (2024.7.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/home/c14210092/Hallo_portrait_image_animation/halloenv2/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install contractions transformers torch tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feb426bf-4328-4e71-a165-226cfd6c6076",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 12:06:52.104125: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-07 12:06:52.118545: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749298012.136441 4184188 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749298012.141739 4184188 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1749298012.155480 4184188 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749298012.155494 4184188 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749298012.155496 4184188 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1749298012.155498 4184188 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-07 12:06:52.159724: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import layers, activations, regularizers, initializers, constraints\n",
    "import tensorflow.keras.backend as K\n",
    "from contractions import fix\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72af4470-3046-49cd-8580-1674baee4150",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc1c13ff-cb5d-4f67-818f-c2319ff0cbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/c14210092/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca850b3a-1c6c-4c43-8c7f-de6c6e05b73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquashActivation(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        s_squared_norm = tf.reduce_sum(\n",
    "            tf.square(inputs), axis=-1, keepdims=True) + tf.keras.backend.epsilon()\n",
    "        scale = tf.sqrt(s_squared_norm) / (0.5 + s_squared_norm)\n",
    "        return scale * inputs\n",
    "\n",
    "    def get_config(self):\n",
    "        return super().get_config()\n",
    "\n",
    "\n",
    "class Capsule(layers.Layer):\n",
    "    def __init__(self, num_capsule, dim_capsule, routings=3, share_weights=True,\n",
    "                 initializer='glorot_uniform', activation=None, regularizer=None, constraint=None, **kwargs):\n",
    "        super(Capsule, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "        self.share_weights = share_weights\n",
    "        self.activation = activations.get(activation)\n",
    "        self.regularizer = regularizers.get(regularizer)\n",
    "        self.initializer = initializers.get(initializer)\n",
    "        self.constraint = constraints.get(constraint)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim_capsule = input_shape[-1]\n",
    "        if self.share_weights:\n",
    "            self.W = self.add_weight(name='capsule_kernel',\n",
    "                                     shape=(1, input_dim_capsule,\n",
    "                                            self.num_capsule * self.dim_capsule),\n",
    "                                     initializer=self.initializer, regularizer=self.regularizer,\n",
    "                                     constraint=self.constraint, trainable=True)\n",
    "        else:\n",
    "            input_num_capsule = input_shape[-2]\n",
    "            self.W = self.add_weight(name='capsule_kernel',\n",
    "                                     shape=(input_num_capsule, input_dim_capsule,\n",
    "                                            self.num_capsule * self.dim_capsule),\n",
    "                                     initializer=self.initializer, regularizer=self.regularizer,\n",
    "                                     constraint=self.constraint, trainable=True)\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs):\n",
    "        if self.share_weights:\n",
    "            u_hat_vectors = K.conv1d(inputs, self.W)\n",
    "        else:\n",
    "            u_hat_vectors = K.local_conv1d(inputs, self.W, [1], [1])\n",
    "\n",
    "        batch_size = K.shape(inputs)[0]\n",
    "        input_num_capsule = K.shape(inputs)[1]\n",
    "        u_hat_vectors = K.reshape(\n",
    "            u_hat_vectors, (batch_size, input_num_capsule, self.num_capsule, self.dim_capsule))\n",
    "        u_hat_vectors = K.permute_dimensions(u_hat_vectors, (0, 2, 1, 3))\n",
    "        routing_weights = K.zeros_like(u_hat_vectors[:, :, :, 0])\n",
    "\n",
    "        for i in range(self.routings):\n",
    "            capsule_weights = K.softmax(routing_weights, 1)\n",
    "            outputs = K.batch_dot(capsule_weights, u_hat_vectors, [2, 2])\n",
    "            if K.ndim(outputs) == 4:\n",
    "                outputs = K.sum(outputs, axis=1)\n",
    "            if i < self.routings - 1:\n",
    "                outputs = K.l2_normalize(outputs, -1)\n",
    "                routing_weights = K.batch_dot(outputs, u_hat_vectors, [2, 3])\n",
    "                if K.ndim(routing_weights) == 4:\n",
    "                    routing_weights = K.sum(routing_weights, axis=1)\n",
    "\n",
    "        return self.activation(outputs)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.num_capsule, self.dim_capsule)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Capsule, self).get_config()\n",
    "        config.update({\n",
    "            'num_capsule': self.num_capsule, 'dim_capsule': self.dim_capsule,\n",
    "            'routings': self.routings, 'share_weights': self.share_weights,\n",
    "            'activation': activations.serialize(self.activation),\n",
    "            'initializer': initializers.serialize(self.initializer),\n",
    "            'regularizer': regularizers.serialize(self.regularizer),\n",
    "            'constraint': constraints.serialize(self.constraint)\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "534ec9e3-382f-4b5d-891a-29b9673d4add",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleToxicClassifier:\n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "        self.tokenizer = None\n",
    "        self.bert_tokenizer = None\n",
    "        self.bert_model = None\n",
    "        self.bert_embeddings = None\n",
    "        self.max_len = 200\n",
    "        self.device = torch.device(\n",
    "            'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.label_names = ['toxic', 'severe_toxic',\n",
    "                            'obscene', 'threat', 'insult', 'identity_hate']\n",
    "        print(f\"Using device: {self.device}\")\n",
    "\n",
    "    def load_tokenizer(self, tokenizer_path):\n",
    "        \"\"\"Load the tokenizer for CNN models\"\"\"\n",
    "        with open(tokenizer_path, 'rb') as f:\n",
    "            self.tokenizer = pickle.load(f)\n",
    "        print(f\"Tokenizer loaded from {tokenizer_path}\")\n",
    "\n",
    "    def load_bert_embeddings(self, embeddings_path):\n",
    "        \"\"\"Load pre-computed BERT embeddings\"\"\"\n",
    "        self.bert_embeddings = np.load(embeddings_path)\n",
    "        print(f\"BERT embeddings loaded: {self.bert_embeddings.shape}\")\n",
    "\n",
    "    def init_bert(self, model_name='bert-base-uncased'):\n",
    "        \"\"\"Initialize BERT embedding computation\"\"\"\n",
    "        self.bert_tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "        self.bert_model = BertModel.from_pretrained(model_name)\n",
    "        self.bert_model = self.bert_model.to(self.device)\n",
    "        self.bert_model.eval()\n",
    "        print(f\"BERT model {model_name} initialized\")\n",
    "\n",
    "    def load_model(self, name, path, model_type):\n",
    "        \"\"\"Load a single model\"\"\"\n",
    "        custom_objects = {'Capsule': Capsule,\n",
    "                          'SquashActivation': SquashActivation}\n",
    "\n",
    "        if 'capsule' in model_type.lower():\n",
    "            model = load_model(path, custom_objects=custom_objects)\n",
    "        else:\n",
    "            model = load_model(path)\n",
    "\n",
    "        self.models[name] = {'model': model, 'type': model_type}\n",
    "        print(f\"Model {name} loaded successfully\")\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"Clean and preprocess text for CNN models\"\"\"\n",
    "        if not isinstance(text, str):\n",
    "            text = str(text)\n",
    "\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'http\\S+|www\\S+', 'url', text)\n",
    "        text = re.sub(r'@\\w+', 'username', text)\n",
    "        text = re.sub(r'[^a-z\\s]', '', text)\n",
    "        text = re.sub(r'\\d+', 'number', text)\n",
    "        text = fix(text)\n",
    "        text = ' '.join(word_tokenize(text))\n",
    "        return text\n",
    "\n",
    "    def get_bert_embedding(self, text):\n",
    "        \"\"\"Get BERT embedding for text\"\"\"\n",
    "        if self.bert_model is None:\n",
    "            raise ValueError(\"BERT model not initialized\")\n",
    "\n",
    "        inputs = self.bert_tokenizer(text, return_tensors='pt', truncation=True,\n",
    "                                     padding=True, max_length=self.max_len).to(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.bert_model(**inputs)\n",
    "\n",
    "        return outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "\n",
    "    def classify_text(self, text):\n",
    "        \"\"\"Main classification function\"\"\"\n",
    "        print(f\"\\nOriginal Text:\\n{text}\\n\")\n",
    "        print(self.label_names)\n",
    "\n",
    "        # Preprocess for CNN models\n",
    "        processed_text = self.preprocess_text(text)\n",
    "        cnn_input = None\n",
    "        if self.tokenizer:\n",
    "            seq = self.tokenizer.texts_to_sequences([processed_text])\n",
    "            cnn_input = pad_sequences(\n",
    "                seq, maxlen=self.max_len, padding='post', truncating='post')\n",
    "\n",
    "        # Get BERT embedding\n",
    "        bert_input = None\n",
    "        if self.bert_model:\n",
    "            bert_input = self.get_bert_embedding(text)\n",
    "\n",
    "        # Store all predictions - explicitly initialize as dictionary\n",
    "        all_predictions = dict()\n",
    "\n",
    "        # Make predictions with all models\n",
    "        for name, model_info in self.models.items():\n",
    "            model = model_info['model']\n",
    "            model_type = model_info['type']\n",
    "\n",
    "            # Initialize prediction variable as None\n",
    "            prediction_result = None\n",
    "\n",
    "            try:\n",
    "                if 'bert' in model_type.lower():\n",
    "                    if bert_input is not None:\n",
    "                        prediction_result = model.predict(\n",
    "                            bert_input, verbose=0)\n",
    "                    else:\n",
    "                        print(\n",
    "                            f\"BERT model {name} requires BERT initialization\")\n",
    "                        continue\n",
    "                else:\n",
    "                    if cnn_input is not None:\n",
    "                        prediction_result = model.predict(cnn_input, verbose=0)\n",
    "                    else:\n",
    "                        print(f\"CNN model {name} requires tokenizer\")\n",
    "                        continue\n",
    "\n",
    "                # Format prediction\n",
    "                if prediction_result.ndim > 1 and prediction_result.shape[0] == 1:\n",
    "                    prediction_result = prediction_result[0]\n",
    "\n",
    "                # Convert to binary predictions\n",
    "                binary_pred = (prediction_result > 0.5).astype(int)\n",
    "\n",
    "                # Store both raw probabilities and binary predictions\n",
    "                all_predictions[name] = {\n",
    "                    'probabilities': prediction_result.tolist(),\n",
    "                    'binary': binary_pred.tolist(),\n",
    "                    'labels': dict(zip(self.label_names, binary_pred.tolist()))\n",
    "                }\n",
    "\n",
    "                print(f\"{name} Prediction: {binary_pred}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error with {name}: {str(e)}\")\n",
    "                all_predictions[name] = {'error': str(e)}\n",
    "\n",
    "        return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89e84842-799e-492b-a4fa-566e64ea0581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup function\n",
    "def setup_classifier(tokenizer_path=None, bert_embeddings_path=None, use_bert=True):\n",
    "    \"\"\"Setup function\"\"\"\n",
    "    classifier = SimpleToxicClassifier()\n",
    "\n",
    "    if tokenizer_path:\n",
    "        classifier.load_tokenizer(tokenizer_path)\n",
    "\n",
    "    if bert_embeddings_path:\n",
    "        classifier.load_bert_embeddings(bert_embeddings_path)\n",
    "\n",
    "    if use_bert and not bert_embeddings_path:\n",
    "        classifier.init_bert()\n",
    "\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e61d99b4-79ac-4598-8b99-ae1c97f53790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Tokenizer loaded from tokenizer.pkl\n",
      "BERT model bert-base-uncased initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1749298016.515963 4184188 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15716 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:31:00.0, compute capability: 8.6\n",
      "I0000 00:00:1749298016.519455 4184188 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 4909 MB memory:  -> device: 1, name: NVIDIA RTX A5000, pci bus id: 0000:4b:00.0, compute capability: 8.6\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model CnnLSTM loaded successfully\n",
      "Model CnnLSTM_Capsule loaded successfully\n",
      "Model BERT_BiGRU loaded successfully\n",
      "Model BERT_BiGRU_Capsule loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Setup classifier\n",
    "classifier = setup_classifier(\n",
    "    # Update with your path\n",
    "    tokenizer_path='tokenizer.pkl',\n",
    "    use_bert=True\n",
    ")\n",
    "# Load models\n",
    "classifier.load_model(\n",
    "    'CnnLSTM', 'model_epoch_02.h5', 'cnn_lstm')\n",
    "classifier.load_model(\n",
    "    'CnnLSTM_Capsule', 'model_dim16_routing3_epoch02.h5', 'cnn_lstm_capsule')\n",
    "classifier.load_model(\n",
    "    'BERT_BiGRU', 'bert_bgru_epoch_09.h5', 'bert_bigru')\n",
    "classifier.load_model('BERT_BiGRU_Capsule',\n",
    "                      'model_dim8_routing3_epoch29.h5', 'bert_bigru_capsule')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09a98d79-b396-42af-94c0-45ac0ce9f04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Text:\n",
      "and you are a motherfucking asshole,suck your dick,you dirty son of a whore\n",
      "\n",
      "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1749298018.632734 4184522 cuda_dnn.cc:529] Loaded cuDNN version 90501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CnnLSTM Prediction: [1 0 1 0 1 0]\n",
      "CnnLSTM_Capsule Prediction: [1 1 1 0 1 0]\n",
      "BERT_BiGRU Prediction: [1 0 1 0 1 0]\n",
      "BERT_BiGRU_Capsule Prediction: [1 1 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "a = classifier.classify_text(\n",
    "    \"and you are a motherfucking asshole,suck your dick,you dirty son of a whore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd60b71e-80f6-47d0-b171-7aee0c6ab42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original Text:\n",
      "YOU NEED SUM PUSSY GO PAY A GIRL SHE WILL TAKE CARE OF YOU, I SAY THIS BECUASE MOST PPL HERE ARE DORKS AND VIRGINS THATS NEVER EVEN TOUCHED THE A FEMALE\n",
      "\n",
      "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
      "CnnLSTM Prediction: [1 0 1 0 1 0]\n",
      "CnnLSTM_Capsule Prediction: [1 0 0 0 0 0]\n",
      "BERT_BiGRU Prediction: [1 0 1 0 1 0]\n",
      "BERT_BiGRU_Capsule Prediction: [1 0 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "b = classifier.classify_text(\n",
    "    \"YOU NEED SUM PUSSY GO PAY A GIRL SHE WILL TAKE CARE OF YOU, I SAY THIS BECUASE MOST PPL HERE ARE DORKS AND VIRGINS THATS NEVER EVEN TOUCHED THE A FEMALE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "356bab30-009a-4d71-be27-74e777ab0140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CnnLSTM': {'probabilities': [0.9433300495147705,\n",
       "   0.028500886633992195,\n",
       "   0.6154075860977173,\n",
       "   0.03338758274912834,\n",
       "   0.534965455532074,\n",
       "   0.06155205890536308],\n",
       "  'binary': [1, 0, 1, 0, 1, 0],\n",
       "  'labels': {'toxic': 1,\n",
       "   'severe_toxic': 0,\n",
       "   'obscene': 1,\n",
       "   'threat': 0,\n",
       "   'insult': 1,\n",
       "   'identity_hate': 0}},\n",
       " 'CnnLSTM_Capsule': {'probabilities': [0.8507922291755676,\n",
       "   0.007761974819004536,\n",
       "   0.3601892292499542,\n",
       "   0.008233538828790188,\n",
       "   0.30752354860305786,\n",
       "   0.026722833514213562],\n",
       "  'binary': [1, 0, 0, 0, 0, 0],\n",
       "  'labels': {'toxic': 1,\n",
       "   'severe_toxic': 0,\n",
       "   'obscene': 0,\n",
       "   'threat': 0,\n",
       "   'insult': 0,\n",
       "   'identity_hate': 0}},\n",
       " 'BERT_BiGRU': {'probabilities': [0.9506295323371887,\n",
       "   0.3133198916912079,\n",
       "   0.8824242949485779,\n",
       "   0.030847379937767982,\n",
       "   0.8201826810836792,\n",
       "   0.16107206046581268],\n",
       "  'binary': [1, 0, 1, 0, 1, 0],\n",
       "  'labels': {'toxic': 1,\n",
       "   'severe_toxic': 0,\n",
       "   'obscene': 1,\n",
       "   'threat': 0,\n",
       "   'insult': 1,\n",
       "   'identity_hate': 0}},\n",
       " 'BERT_BiGRU_Capsule': {'probabilities': [0.9605139493942261,\n",
       "   0.09423692524433136,\n",
       "   0.777413010597229,\n",
       "   0.029769841581583023,\n",
       "   0.6840382218360901,\n",
       "   0.08225160092115402],\n",
       "  'binary': [1, 0, 1, 0, 1, 0],\n",
       "  'labels': {'toxic': 1,\n",
       "   'severe_toxic': 0,\n",
       "   'obscene': 1,\n",
       "   'threat': 0,\n",
       "   'insult': 1,\n",
       "   'identity_hate': 0}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2d4f4fa-c884-4633-b443-1118a56c6afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_function(message):  # hanya untuk cek\n",
    "    print(\"Hello from a function\")\n",
    "    testAdd = \"ok\"\n",
    "    message = message + testAdd\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e30a84a5-1477-43ff-9d75-e6cdaaa09e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Tokenizer loaded from tokenizer.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model CnnLSTM loaded successfully\n",
      "Model CnnLSTM_Capsule loaded successfully\n",
      "Model BERT_BiGRU loaded successfully\n",
      "Model BERT_BiGRU_Capsule loaded successfully\n",
      "BERT model bert-base-uncased initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize classifier globally (add this at the top of your script)\n",
    "classifier = SimpleToxicClassifier()\n",
    "# Load your models here\n",
    "classifier.load_tokenizer('tokenizer.pkl')\n",
    "classifier.load_model(\n",
    "    name='CnnLSTM',\n",
    "    path='model_epoch_02.h5',\n",
    "    model_type='cnn_lstm'\n",
    ")\n",
    "\n",
    "# CNN LSTM Capsule Model\n",
    "classifier.load_model(\n",
    "    name='CnnLSTM_Capsule',\n",
    "    path='model_dim16_routing3_epoch02.h5',\n",
    "    model_type='cnn_lstm_capsule'\n",
    ")\n",
    "\n",
    "# BERT BiGRU Model\n",
    "classifier.load_model(\n",
    "    name='BERT_BiGRU',\n",
    "    path='bert_bgru_epoch_09.h5',\n",
    "    model_type='bert_bigru'\n",
    ")\n",
    "\n",
    "# BERT BiGRU Capsule Model\n",
    "classifier.load_model(\n",
    "    name='BERT_BiGRU_Capsule',\n",
    "    path='model_dim8_routing3_epoch29.h5',\n",
    "    model_type='bert_bigru_capsule'\n",
    ")\n",
    "\n",
    "classifier.init_bert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "753ddd98-b1c1-4b0a-b31c-3d99c60a4c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_comment(comment, username, id, user_mention):\n",
    "    \"\"\"Updated to use global classifier - maintains original function signature\"\"\"\n",
    "    global classifier\n",
    "\n",
    "    # Get predictions from the classifier\n",
    "    results = classifier.classify_text(comment)\n",
    "\n",
    "    check = False\n",
    "    header = (\n",
    "        f\"**Message:** {comment}\\n\"\n",
    "        f\"**Username:** {username}\\n\"\n",
    "        f\"**ID:** {id}\\n\"\n",
    "        f\"{user_mention}\\n\\n\"\n",
    "        \"```\"\n",
    "    )\n",
    "\n",
    "    labels = ['toxic', 'severe_toxic', 'obscene',\n",
    "              'threat', 'insult', 'identity_hate']\n",
    "    body = ''\n",
    "\n",
    "    # Process results from each model\n",
    "    for model_name, prediction_data in results.items():\n",
    "        # Skip models that had errors\n",
    "        if 'error' in prediction_data:\n",
    "            body += f\"Model: {model_name}\\n\"\n",
    "            body += f\"Error: {prediction_data['error']}\\n\\n\"\n",
    "            continue\n",
    "\n",
    "        body += f\"Model: {model_name}\\n\"\n",
    "        body += f\"{'Label':<16}\\t{'Flag':<8}\\tScore\\n\"\n",
    "        body += f\"{'-'*40}\\n\"\n",
    "\n",
    "        probabilities = prediction_data['probabilities']\n",
    "        binary_predictions = prediction_data['binary']\n",
    "\n",
    "        for idx, label in enumerate(labels):\n",
    "            if idx < len(probabilities):  # Safety check\n",
    "                score = probabilities[idx]\n",
    "                is_flagged = binary_predictions[idx] == 1\n",
    "                body += f\"{label:<16}\\t{str(is_flagged):<8}\\t{score:.2f}\\n\"\n",
    "                if is_flagged:\n",
    "                    check = True\n",
    "        body += '\\n'\n",
    "\n",
    "    if not check:\n",
    "        return '**FALSE**'  # No toxic content detected\n",
    "    else:\n",
    "        return header + body + '```'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dac2feb-18f6-4882-8a7d-beeb5e55a6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from discord.utils import utcnow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a44247f-ee9c-4b8e-87e0-25552d9dad4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:discord.client:PyNaCl is not installed, voice will NOT be supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as Toxic Detection Bot\n",
      "\n",
      "Original Text:\n",
      "test\n",
      "\n",
      "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f4e48e42f20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f4e48e42f20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CnnLSTM Prediction: [0 0 0 0 0 0]\n",
      "WARNING:tensorflow:6 out of the last 10 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f4e48e42fc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 10 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7f4e48e42fc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CnnLSTM_Capsule Prediction: [0 0 0 0 0 0]\n",
      "BERT_BiGRU Prediction: [0 0 0 0 0 0]\n",
      "BERT_BiGRU_Capsule Prediction: [0 0 0 0 0 0]\n",
      "\n",
      "Original Text:\n",
      "fuckk you\n",
      "\n",
      "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
      "CnnLSTM Prediction: [1 0 0 0 0 0]\n",
      "CnnLSTM_Capsule Prediction: [0 0 0 0 0 0]\n",
      "BERT_BiGRU Prediction: [1 0 1 0 1 0]\n",
      "BERT_BiGRU_Capsule Prediction: [1 0 1 0 1 0]\n",
      "User mixlin timed out until 2025-06-07 12:08:32.433773+00:00\n",
      "\n",
      "Original Text:\n",
      "fuck off\n",
      "\n",
      "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
      "CnnLSTM Prediction: [1 0 1 0 1 0]\n",
      "CnnLSTM_Capsule Prediction: [1 0 1 0 1 0]\n",
      "BERT_BiGRU Prediction: [1 0 1 0 1 0]\n",
      "BERT_BiGRU_Capsule Prediction: [1 0 0 0 0 0]\n",
      "User mixlin timed out until 2025-06-07 12:08:48.780144+00:00\n",
      "\n",
      "Original Text:\n",
      "nigga\n",
      "\n",
      "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
      "CnnLSTM Prediction: [1 0 0 0 0 0]\n",
      "CnnLSTM_Capsule Prediction: [1 0 0 0 0 0]\n",
      "BERT_BiGRU Prediction: [1 0 0 0 0 0]\n",
      "BERT_BiGRU_Capsule Prediction: [1 0 0 0 0 0]\n",
      "User mixlin timed out until 2025-06-07 12:09:06.612385+00:00\n",
      "\n",
      "Original Text:\n",
      "fuck\n",
      "\n",
      "['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
      "CnnLSTM Prediction: [1 0 1 0 1 0]\n",
      "CnnLSTM_Capsule Prediction: [1 0 1 0 1 0]\n",
      "BERT_BiGRU Prediction: [1 0 0 0 0 0]\n",
      "BERT_BiGRU_Capsule Prediction: [0 0 0 0 0 0]\n",
      "User mixlin timed out until 2025-06-07 12:09:31.067975+00:00\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "import discord\n",
    "\n",
    "# setting beberapa parameter discord bot nya agar bisa mengirim/ membaca message\n",
    "intents = discord.Intents.default()\n",
    "intents.messages = True\n",
    "intents.message_content = True\n",
    "\n",
    "client = discord.Client(intents=intents)\n",
    "\n",
    "# inisialisasi token bot\n",
    "BOT_TOKEN = 'xxx'\n",
    "\n",
    "\n",
    "async def send_hello_world(channel, message):\n",
    "    if message == '':  # hanya untuk message yang memang tidak ada message :D\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        await channel.send(message)  # melihat apakah message sudah di send\n",
    "    except Exception as e:\n",
    "        # mengembalikan error jika terjadi error\n",
    "        print(f\"Error sending message: {e}\")\n",
    "\n",
    "\n",
    "@client.event\n",
    "async def on_ready():\n",
    "    print(f'Logged in as {client.user.name}')\n",
    "\n",
    "\n",
    "@client.event\n",
    "async def on_message(message):\n",
    "    if message.author == client.user:\n",
    "        return\n",
    "\n",
    "    # if message.content.startswith('$hello'):\n",
    "    #     channel = message.channel\n",
    "    #     task = client.loop.create_task(send_hello_world(channel, 'hellooooooooooooo' ))\n",
    "\n",
    "    if client.user in message.mentions and 'general' in str(message.channel):\n",
    "        channel = message.channel\n",
    "\n",
    "        # cuma buat mengecek apa bot aktif, kalau iya bot akan mengirim reply jika di tag\n",
    "        reply = my_function('haiiiiiiiiiiiasdj,kasdjl')\n",
    "\n",
    "        task = client.loop.create_task(send_hello_world(channel, reply))\n",
    "        await task\n",
    "\n",
    "    if 'general' in str(message.channel):\n",
    "        content = message.content\n",
    "        user_name = message.author.name\n",
    "        user_id = message.author.id\n",
    "        user_mention = message.author.mention\n",
    "\n",
    "        try:\n",
    "            reply = score_comment(\n",
    "                content, user_name, user_id, user_mention)\n",
    "\n",
    "            if reply != '**FALSE**':  # toxic content found\n",
    "\n",
    "                # ⏳ Timeout the user\n",
    "                timeout_until = utcnow() + timedelta(minutes=.1)\n",
    "                await message.author.edit(timed_out_until=timeout_until, reason=\"Toxic message detected\")\n",
    "                print(f\"User {user_name} timed out until {timeout_until}\")\n",
    "\n",
    "                # 🚫 Delete the message\n",
    "                await message.delete()\n",
    "\n",
    "                # 🛡️ Optional: Ban the user\n",
    "                # await message.author.ban(reason=\"Toxic message\", delete_message_days=1)\n",
    "\n",
    "                # 📢 Report to 'reports' channel\n",
    "                reply_channel = client.get_channel(1251881766256509049)\n",
    "                await reply_channel.send(reply)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing message: {e}\")\n",
    "\n",
    "\n",
    "async def start_bot():  # untuk mengaktifkan bot dengan token yang sudah di inisialisasi di atas\n",
    "    await client.start(BOT_TOKEN)\n",
    "\n",
    "# Run the bot using asyncio in a Jupyter Notebook\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "async def run_bot():\n",
    "    await start_bot()\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "# bagian sini itu intinya bot nya bisa nyala selama servernya nyala sih, mau di Jupyter/collab mirip2. Kalau di jupyter, server dari laptop sendiri. Kalau collab, ya dari google nya\n",
    "loop.run_until_complete(run_bot())\n",
    "# Aku sudah nyoba kalau ini tidak dilakukan, bot kadang mati sendiri meski server masih nyala. Selama code ini kupakai, tidak pernah mati unless memang di stop notebooknya.\n",
    "\n",
    "# To stop the bot later (optional)\n",
    "client.close()\n",
    "loop.run_until_complete(client.logout())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22be8721-1066-4856-a9d8-5cfa14c4086a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10732eef-9dce-491d-b119-d9d7b600e677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c6766e-d5c8-4aae-9773-c0556645645b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "halloenv2",
   "language": "python",
   "name": "halloenv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
